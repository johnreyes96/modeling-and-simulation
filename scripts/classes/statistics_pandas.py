# -*- coding: utf-8 -*-
"""StatisticsPandas.ipynb

Automatically generated by Colaboratory.

# Estadística Descriptiva y Pandas

## 1. Estadística Descriptiva

La Estadística Descriptiva nos sirve para comenzar a analizar y entender un conjunto de datos. En el caso de datos numéricos, lo hace obteniendo *valores estadísticos* que, de alguna forma, reemplazan a nuestros datos. Por ejemplo, es muy difícil leer y *entender* la edad de 1000 personas. Pero con un grupo reducido de valores estadísticos (mínimo, máximo, media y desviación estándar, etc.) podemos aproximarnos a ese conjunto de una manera mucho más comprensible. Veamos dos medidas muy importantes:

**Promedio**

Dados $n$ números $x_1,x_2,...,x_n$, el promedio o media es

$$\overline{x} = \frac{1}{n}\sum_{i=1}^{n} x_i = \frac{x_1 + x_2 + ... + x_n}{n}$$

**Desviación Estándar**

La varianza y la desviación estándar nos dan una idea de cuán "dispersos" están los valores con respecto a su promedio.

$$ Var = \frac{\sum_{i=1}^{n} (x_i -\overline{x})^2}{n - 1}$$

La desviación estándar es la raiz cuadrada de la varianza. En general se usa la letra griega $\sigma$ para representarla o las siglas $SD$:

$$ SD = \sqrt{\frac{\sum_{i=1}^{n} (x_i -\overline{x})^2}{n - 1}}$$

$$ SD = \sqrt{Var}$$


**Comentarios**:
1. Dado un conjunto de números, el promedio suele ser considerado el número más representativo de ese conjunto. Esto no siempre es así. Pensá o googleá por qué.
2. Al conjunto de números $x_1,...,x_n$ los pueden encontrar por el nombre de *población* o *muestra* (¡Ojo que no estamos diciendo que *población* y *muestra* sean lo mismo!).

### 1.1 Aplicación de las ecuaciones
"""

import numpy as np

# Promedio
x_s = [1, 2, 3, 1, 2, 2, 3, 4, 1, 2, 3, 4, 1, 2, 4]

promedio = sum(x_s) / len(x_s)
print(promedio)

# Varianza y desviación estandar
a = 0
for x in x_s:
    a = a + (x - promedio) ** 2

varianza = a / (len(x_s) - 1)
desviacion = varianza ** 0.5

print(varianza)
print(desviacion)

"""### 1.2 Estadística con NumPy

Veamos cómo se calculan, en NumPy, el promedio, varianza y desviación estándar sobre un arreglo.
"""

x_s = np.array([1, 2, 3, 1, 2, 2, 3, 4, 1, 2, 3, 4, 1, 2, 4])

# Promedio
print(x_s.mean())

# Varianza
print(x_s.var(ddof=1))

# Desviación estándar
print(x_s.std(ddof=1))

"""¿Qué es el parámetro `ddof` de esa función?

¿Qué son los grados de libertad?

En la estadística inferencial, el término grados de libertad se define normalmente como el número de observaciones que son libres de variar, dada una o más restricciones matemáticas, en un conjunto de valores utilizados para estimar alguna característica de la población.

Dicho de otra manera, los grados de libertad son el número de observaciones independientes menos el número de restricciones asociado a esas observaciones.

Grados de libertad en el cálculo de la varianza muestral
Seguramente, la primera vez donde nos encontramos este concepto es a la hora de calcular la varianza de una muestra, medida que representa la variabilidad de un conjunto de datos de una muestra y que se calcula mediante la siguiente fórmula:

  \begin{align*}s^2 = \frac{1}{n-1} \sum_{i=1}^n (x_i - \overline{x})^2\end{align*}

donde

- $x_i$ es valor la observación número i.
- $x̄$ es la media de la muestra.
- $n$ es el número de observaciones en la muestra.

En esta formula, los grados de libertad se encuentran en el denominador y equivalen al número de observaciones menos 1 $(n – 1)$, por lo que solo tenemos una única restricción.

Esta restricción se debe a que para calcular la varianza muestral es necesario calcular previamente la media de la muestra $(x̄)$, por lo que el último valor y única observación que no es libre de variar, se puede obtener fácilmente utilizando el resto de observaciones.

##Ejemplo


El primer día, puede usar cualquiera de los 7 sombreros. El segundo día, puede elegir entre los 6 sombreros restantes, el tercer día puede elegir entre 5 sombreros y así sucesivamente.

Cuando llega al día 6, todavía tiene la opción de escoger entre 2 sombreros que no ha usado todavía esa semana. Pero después de escoger su sombrero para el día 6, no tiene ninguna opción disponible para el sombrero que utilizará el día 7. Debe usar el sombrero restante. Tenía $7-1 = 6$ días de libertad de “sombreros” respecto a la variación del sombrero que podía utilizar.

Ese es el tipo de idea que apoya el concepto de grados de libertad en estadística. Los grados de libertad se definen frecuentemente como el número de observaciones (piezas de información) en los datos que pueden variar libremente al estimar parámetros estadísticos.

##Ejemplo

Imaginemos que tenemos una muestra con 5 observaciones, sabemos que la media muestral corresponde a 8 y queremos calcular la varianza muestral. La restricción que se debe cumplir consiste en que la suma de todos los datos $(x_1 + x_2 + x_3 + x_4 + x_5)$ debe ser igual a $n × x̄$, en este caso, $5 × 8 = 40$.

Otra manera de verlo es que la suma de las desviaciones de las observaciones con respecto a la media $(x_1 – x̄, x_2 – x̄, x_3 – x̄, x_4 – x̄, x_5 – x̄)$ debe ser igual a cero.

Con esta restricción, tenemos que los primeros 4 valores pueden ser cualquier número, pero para que los 5 valores sumen 40, el último valor no puede variar. Por lo tanto, tenemos 4 grados de libertad.

Así, si los primeros 4 valores son $6, 6, 8, 10$, sabemos automáticamente que el último valor corresponde a 10, ya que la suma de los 5 números debe ser igual a 40. Así de simple.

NumPy también puede calcular percentil, cuantil, mínimos y máximos:
"""

x_s = np.array([1, 2, 3, 1, 2, 2, 3, 4, 1, 2, 3, 4, 1, 2, 4])

print(np.percentile(x_s, 75))
print(np.quantile(x_s, 0.5))
print(np.min(x_s))
print(np.max(x_s))

"""

### 1.3 Generación de muestras al azar

Una cosa sumamente útil que podemos hacer con NumPy es generar muestras al azar. Esto no permite simular situaciones. Estas funciones las encontramos dentro del paquete `random` de NumPy, cuya documentación pueden encontrar [aquí](https://docs.scipy.org/doc/numpy-1.15.0/reference/routines.random.html)."""

muestras_dado = np.random.randint(1, 7, size=15)
print(muestras_dado)

### También se puede
muestras_dado = np.random.choice([1, 2, 3, 4, 5, 6], size=15)
print(muestras_dado)

"""**Ejercicio 1:** ¿Cuál será el promedio de los valores obtenidos al tirar muchas veces un dado? Vamos a tratar de responder esta pregunta **simulando** un dado. Para ello:
* Obtener muestras al azar de un dado.
* Calcular su promedio y desviación estándar.

¿A partir de qué cantidad de muestras el promedio se "estabiliza"?
"""

dados = np.random.choice([1, 2, 3, 4, 5, 6], size=10000)
desviacion = dados.std()
promedio = dados.mean()

# print(dados)
# print(dados)
print(desviacion)
print(promedio)

"""**Ejercicio 2:** Simular un dado cargado para favorecer un valor de su elección. Por ejemplo, el seis. Para ello, consultar la ayuda de la función `np.random.choice`. ¿Cómo se modifica el promedio y la desviación estándar?"""

dados = np.random.choice([1, 2, 3, 4, 5, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6, 6], size=50)
desviacion = dados.std()
promedio = dados.mean()

print(dados)
print(desviacion)
print(promedio)

"""Crear un arreglo que asigne probabilidades a cada valor del dado. Recordar que las probabilidades deben sumar 1"""

probabilidades = np.array([1, 1, 1, 1, 1, 6])
probabilidades = probabilidades / probabilidades.sum()
print(probabilidades)

"""Generar las muestras"""

muestras_dado_cargado = np.random.choice([1, 2, 3, 4, 5, 6], p=probabilidades, size=1000)

print(muestras_dado_cargado.mean())
print(muestras_dado_cargado.std())

"""## 2. Pandas

Pandas es la librería más conocida de Python para manipular y analizar datos. Está montada sobre NumPy, por lo cual muchas funcionalidades son similares. Utilizaremos Pandas para trabajar con datasets estructurados (y bueno, ¡bastante más!).

Así como NumPy nos proveé de los *arreglos* y con ellos accedemos a muchas nuevas funcionalidades, Pandas nos provee de los *Data Frames* y las *Series*. El objeto más utilizado es el primero, los Data Frames.

### 2.1 Primeros pasos

Importamos la librería.
"""

import pandas as pd

"""Como primer paso, vamos a crear nuestro propio dataset.

Nota: la población está en número de habitantes y la superficie en km2.




"""

data_dic = {"Departamento": ["Tolima", "Antioquia", "Cundinamarca", "Choco", "Nariño", "Cauca", "Risaralda", "Bolivar",
                             "Quindio", "Caldas", "Santander",
                             "Santa Fe"],
            "Poblacion": [2890151, 1525084, 3670828, 105559, 199633, 308876, 673307, 738929,
                          111593, 638645, 273964, 314537], "Superficie":
                [20780, 307521, 102606, 99633, 509108, 165321, 53219, 148827, 29801, 203013, 243943, 133007]}

# Creamos el DataFrame
data_pandas = pd.DataFrame(data_dic)
print(data_pandas)

"""Devuelve los primeros elementos de la estructura (los primeros valores en el caso de una serie y las primeras filas en el caso de un dataframe). Por defecto, se trata de los 5 primeros elementos, pero podemos especificar el número que deseamos como argumento de la función.

"""

print(data_pandas.head())

"""Son semejantes a los anteriores, pero muestran los últimos elementos de la estructura. Si no indicamos otra cosa como argumento, serán los 5 últimos elementos los que se muestren."""

print(data_pandas.tail())

"""Este método devuelve una estructura conteniendo los valores presentes en la serie y el número de ocurrencias de cada uno. Estos valores se muestran en orden decreciente"""

print(data_pandas.count())

"""Devuelve el número de filas y columnas del DataFrame."""

print(data_pandas.shape)

"""Agregar al Dataset la información correspondiente a algún departamento faltante. Recuerden que, al tratarse de una nueva instancia, corresponde a una fila. **Nota:** "add row to pandas dataframe"."""

# data_dic = {"Departamento":" ","Poblacion":000,"Superficie":000}

data_dic2 = {"Departamento": "Valle", "Poblacion": 218181, "Superficie": 618481}
data_dic2_pandas = pd.DataFrame([data_dic2])
data_pandas = pd.concat([data_pandas, data_dic2_pandas], ignore_index=True)
print(data_pandas)

"""Tenemos que proporcionar el parámetro «ignore_index=True» o añadir la fila, que es la Serie con un nombre."""

data_dic3 = pd.Series({"Departamento": "prueba", "Poblacion": 2481, "Superficie": 6481}, name='x')
data_dic3_pandas = pd.DataFrame([data_dic3])
data_pandas = pd.concat([data_pandas, data_dic3])
print(data_pandas)

"""Devuelve una lista con los nombres de las columnas del DataFrame."""

print(data_pandas.columns)

"""Devuelve una lista con los nombres de las filas del DataFrame."""

print(data_pandas.index)

"""Operaciones con DataFrames


"""

print(data_pandas['Departamento'])

print(data_pandas[['Departamento', 'Poblacion']])

print(data_pandas.Departamento)

print('PoblacioOn' in data_pandas)

print(data_pandas[data_pandas.Poblacion > 500000])

print(data_pandas[(data_pandas.Poblacion > 500000) & (data_pandas.Superficie < 150000)])

data_pandas['Densidad'] = data_pandas['Poblacion'] / data_pandas['Superficie']
print(data_pandas)

"""## 2.3 Iris dataset

Vamos a trabajar con el Iris Dataset, probablemente uno de los conjuntos de datos más famosos, ya que muchos ejemplos se realizan con él. Es un dataset sencillo pero ilustrativo.


1. Abrir con Pandas el archivo 'iris.csv' e imprimir sus primeros cinco elementos. Pista: `pd.read...()`.

Dataset  Github [aqui](https://gist.github.com/curran/a08a1080b88344b0c8a7).

Dataset Kaggle [aqui](https://www.kaggle.com/datasets/uciml/iris).

Montar unidad de Drive
"""

iris_data = pd.read_csv('../../data/Iris.csv')
# iris_data = pd.read_csv('/content/gdrive/My Drive/Colab Notebooks/Iris.csv')·
# example = pd.read_csv('https://aqui la direccion con el archivo example.csv')

print(iris_data)

"""Utilizando las funciones anteriores veremos cuantos datos tiene este dataset."""

print(iris_data.info())

print(iris_data.shape)

print(iris_data.columns)

"""Calculando algunos valores estadisticos."""

# Se agrega porque actualmente está sacando error TypeError: Could not convert ['Iris-setosa'] to numeric
iris_data.drop(columns=['Species'], inplace=True)
print(iris_data.mean())

media = iris_data['PetalLengthCm'].mean()
print(media)

print(iris_data.var())

print(iris_data.std())

print(iris_data.min())

print(iris_data.max())

print(iris_data.sum())

"""Una de las funciones mas importantes es df.descrive, devuelve un DataFrame con un resumen estadístico de las columnas del DataFrame. Para los datos numéricos (number) se calcula la media, la desviación típica, el mínimo, el máximo y los cuartiles. Para los datos no numéricos (object) se calcula el número de valores, el número de valores distintos, la moda y su frecuencia. Si no se indica el tipo solo se consideran las columnas numéricas."""

print(iris_data.describe())

"""###Funciones iloc y loc

Existen diferentes formas de seleccionar los registros de las filas y columnas. Siendo dos de las más importantes iloc y loc. La primera permite seleccionar los elementos en base a la posición, mientras que la segunda permite seleccionar mediante etiquetas o declaraciones condicionales.
"""

print(iris_data.iloc[0])  # Primera fila

print(iris_data.iloc[1])  # Segunda fila

print(iris_data.iloc[-1])  # Última fila

print(iris_data.iloc[:, 0])  # Primera columna

print(iris_data.iloc[:, 1])  # Segunda columna

print(iris_data.iloc[:, -1])  # ultima columna

print(iris_data.iloc[0:5])  # Primeras cinco filas

print(iris_data.iloc[:, 0:5])  # Primeras cinco columnas

print(iris_data.iloc[[0, 2, 1]])  # Primera, tercera y segunda filas

print(iris_data.iloc[:, [0, 2, 1]])  # Primera, tercera y segunda columnas

"""Ahora el loc"""

print(iris_data.columns)

print(iris_data.loc[:, 'Id'])

# Se saca por nueva versión de numpy
# print(iris_data.loc[:, 'Species'])

# setosa = iris_data.loc[:, 'Species'] == 'Iris-setosa'
# df_setosa = iris_data.loc[setosa]
# df_setosa.head()

"""##Ejercicio
Buscar que hacen las siguientes funciones:

`inplace`, `drop`, `del`.

Y realizar ejemplos con ellas.

"""

# Cambiar de nombre una columna de manera definitiva
iris_data.rename(columns={'Id': 'Indice'},
                 inplace=True)
print(iris_data)

# Eliminar columnas
iris_data2 = iris_data.drop(columns=['SepalWidthCm', 'PetalWidthCm'])
print(iris_data2)

# Eliminar filas
iris_data2 = iris_data.drop([0, 1])
print(iris_data2)

# Eliminar una columna en definitiva
del iris_data['PetalWidthCm']
print(iris_data)
